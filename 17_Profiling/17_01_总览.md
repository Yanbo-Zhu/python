
- the process of identifying performance bottlenecks is called **profiling**
- a straight-forward way to time some specific code directly from within jupyter notebooks is to use the `%timeit` magic command


# 1 The `%timeit` magic command
- to demonstrate `%timeit` take these three different implementations for prime number search, which we load by running or local `primes.py` file


直接测量某一个 method 的 耗时 

![](images/Pasted%20image%2020241110174947.png)


# 2 Analysing your code (inspect module)


- the most basic way to identify bottlenecks is by static code analysis
- let us try understand why the first implementation of finding all primes up to a limit is so slow  
- we can use the `inspect` module to specifically get the source code of some function

find_primes是自己定义的一个function

![](images/Pasted%20image%2020241110175225.png)



# 3 Profiling (cProfile)

- `%timeit` and simple static code analysis is quite limited and may not easily lead us to bottlenecks

- the profiling module is called `cProfile` (c-implementation of profile)  
- we can call the `run` function on a Python-expressions written in a string to create profiling statistics on this expression  
- the second argument is the file in which we store the statistics


```python
import cProfile  
  
cProfile.run('find_primes(1000)', 'find_primes.profile')
```

statistic 会存在 find_primes.profile 中,   find_primes.profile 是自动生成的 

## 3.1 Profiling Statistics ( `pstats` (profiling-stats) module )

- the `pstats` (profiling-stats) module provides us with functions to analyse the profiling results


- When printing the output of the statistics, we see several columns:  
    - `ncalls`: The number of calls made to the function/method.  
    - `tottime`: The total time spent in the function/method excluding time spent in calls to sub-functions.  
    - `percall`: The average time spent in the function/method per call (tottime / ncalls).  
    - `cumtime`: The cumulative time spent in the function/method, including time spent in calls to sub-functions.  
    - `percall`: The average cumulative time spent in the function/method per call (cumtime / ncalls).  
    - `filename`:lineno(function): The filename, line number, and function name.

- we can create a `Stats` instance by supplying a file name to the constructor  
- calling the `sort_stats` method allows us to sort by specific statistic columns  
- the `print_stats` method will then print a formatted table
- `divides` checks whether a number is divisible by another, can we reduce the number of these calls?


```
import pstats  
stats = pstats.Stats('find_primes.profile')  
  
stats.strip_dirs().sort_stats('ncalls').print_stats(10);
```

![](images/Pasted%20image%2020241110180001.png)



## 3.2 Faster way of finding primes


- the `find_primes_fast` is slightly more optimized

```python
print(inspect.getsource(is_prime))  
print(inspect.getsource(find_primes_faster))
```



## 3.3 Profiling faster way of finding primes

```python
cProfile.run("find_primes_faster(1000)", 'find_primes_faster.profile')  
  
stats = pstats.Stats('find_primes_faster.profile')  
  
stats.strip_dirs().sort_stats('ncalls').print_stats(10);
```

```
   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     2917    0.001    0.000    0.001    0.000 primes.py:3(divides)
      999    0.002    0.000    0.002    0.000 primes.py:18(is_prime)
      168    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.003    0.003 {built-in method builtins.exec}
        1    0.000    0.000    0.003    0.003 <string>:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.003    0.003 primes.py:33(find_primes_faster)
```

- we can see that the number of calls to `divides` halved